---
permalink: /embedding-spaces-lab-autonomous/
---

The autonomous laboratory is open for your exploration. Using the basic codes provided in the guided laboratory, students can modify it to run different experiments. You encoirage you to explore whatever experiments you find most interesting. Follows an incomplete list of suggestions that you may or may not consider:

# Word Embeddings
- Consider embeddings obtained from different training corpus
- Study the differences between the embeddings of different lengths
- Play with different distance measures, and explore the results
- Seek for new regularities. Is there a pattern? What defines a regularity?
- Use word embeddings for other purposes (e.g., document classification, clustering, etc.), by applying other tools on top of them (e.g., a shallow network, a SVM, K-means, etc.)
- Train word embeddings using a corpus (challenging)
- Train doc embeddings using a corpus (challenging)

# Image Embeddings
- Extract the embeddings of different sets of images. From available datasets or any set you want (e.g., you want to cluster your holiday photos?)
- Generate embeddings using different sets of layers. Whats the difference between embeddings of early and late layers? What about the full-network embedding?
- Apply image embeddings to solve classification and/or clustering tasks.
- Consider using a different pre-trained model as source. You can use a model trained by you (e.g., for CIFAR or MNIST, or for any other dataset), or you can find pre-trained models online.

# Other
- Deploying and executing a multimodal pipeline, which combines both image and textual embeddings. Try to solve image captioning and image retrieval tasks of any set of images.
- Any other relevant task, motivated by the other resources linked in the guided lab page.



